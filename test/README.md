# Lifelong Learning Logger Tests

There are several unit tests available, in the `test_simple_logging.py` file.

The unit tests can be run by ensuring the virtual environment is active, then
executing the following commands:

```bash
cd test
python test_simple_logging.py
```

## Test Summaries

- `testErrorInit`
  - tests a variety of erroneous calls to the constructor of DataLogger,
  including:
    - `logger_info` not being a dict
    - `metrics_columns` field not mapping to a list of non-empty strings
    - `metrics_columns` missing as a field
-`testValidRecord`
    - ensures valid sequences of calls to `log_record` do not throw errors,
    including:
      - logging the same record twice in a row
      - increasing `exp_num`
      - increasing `block_num`
- `testErrorRecord`
  - ensures erroneous sequences of calls to `log_record` do throw errors:
    - missing various expected fields
    - trying to override `timestamp`
    - adding extra columns in a later call
    - invalid sequences of `block_num` and `exp_num`
    - invalid `worker_id`
    - `task_params` not being JSON serializable

## Log Validation

Logs generated by L2Logger should already be in the proper format for ingestion by the Metrics Framework. However, log validation can also be done manually using the provided `validate_log.py` script.

```
usage: validate_log.py [-h] -l LOG_DIR

Validate log format from the command line

required arguments:
  -l LOG_DIR, --log-dir LOG_DIR
                        Log directory of scenario

optional arguments:
  -h, --help            show this help message and exit
```

Note: This script only validates one instance of a scenario output; it does not run recursively on a directory containing multiple scenario logs.
